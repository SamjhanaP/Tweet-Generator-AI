{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweets Cleaner STEPS\n",
    "\n",
    "1. @mentions\n",
    "2. url links\n",
    "3. hashtag - remove #only but keep text\n",
    "4. punctuation\n",
    "5. stop words\n",
    "6. Replace abbreviations and some spell correction [Cleaning]\n",
    "7. Capitalization or lowercase\n",
    "\n",
    "{tokenization}\n",
    "{Stemming and Lammitization}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gingerit in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (0.8.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.25.1 in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from gingerit) (2.26.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.25.1->gingerit) (1.25.11)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0; python_version >= \"3\" in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.25.1->gingerit) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.25.1->gingerit) (2020.6.20)\n",
      "Requirement already satisfied: idna<4,>=2.5; python_version >= \"3\" in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from requests<3.0.0,>=2.25.1->gingerit) (2.10)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install gingerit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: tqdm in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "Requirement already satisfied: click in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: regex in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: joblib in /Users/apple/opt/anaconda3/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/apple/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from tweet_cleaner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " How are you\n",
      " this is a text with link\n",
      "This tweet has tag cool\n",
      "Hello how are you Khana khake jana ha\n",
      "This sample sentence , showing stop words filtration .\n",
      "I'm about to go to school with her carrying flowers\n",
      "i'm abt to go to school wt her carrying flowrs\n"
     ]
    }
   ],
   "source": [
    "print(removeMention(\"@billgates How are you\"))\n",
    "print(removeUrl(\"https://google.com this is a text with link\"))\n",
    "print(removeHashtag(\"This tweet has tag #cool\"))\n",
    "print(removePunctuation(\"Hello! how are you? Khana khake jana ha!!\"))\n",
    "print(removeStopWords(\"This is a sample sentence, showing off the stop words filtration.\"))\n",
    "print(fixSlangAndSpelling(\"I'm abt to go to school wt her carrying flowrs\"))\n",
    "print(changeToLower(\"I'm abt to go to school wt her carrying flowrs\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet clean\n",
    "using the functions defined above a master function is created which cleans one tweet at a time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changeToLower: \n",
      "@ragu, how are you? you can find me at https://www.johndoe.com. please contct asap, you are the inspiratin to many peopls!!, #inspired #fans\n",
      "\n",
      "removeMention: \n",
      ", how are you? you can find me at https://www.johndoe.com. please contct asap, you are the inspiratin to many peopls!!, #inspired #fans\n",
      "\n",
      "removeUrl: \n",
      ", how are you? you can find me at  please contct asap, you are the inspiratin to many peopls!!, #inspired #fans\n",
      "\n",
      "removeHashtag: \n",
      ", how are you? you can find me at  please contct asap, you are the inspiratin to many peopls!!, inspired fans\n",
      "\n",
      "removePunctuation: \n",
      " how are you you can find me at  please contct asap you are the inspiratin to many peopls inspired fans\n",
      "\n",
      "removeStopWords: \n",
      "find please contct asap inspiratin many peopls inspired fans\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'find please contct asap inspiratin many peopls inspired fans'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleanTweet(\n",
    "    \"@ragu, how are you? you can find me at https://www.johndoe.com. Please contct asap, you are the inspiratin to many peopls!!, #inspired #fans\", \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data \n",
    "df = load_data.get_tweets(\"billgates\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      You were a good sport, Jimmy. Pro tip...never ...\n",
       "1      The Gates Foundation is providing additional, ...\n",
       "2      Over the years, I’ve shared a stage with a jar...\n",
       "3      I’ve been rewatching some of my favorite movie...\n",
       "4      Getting an early start on my weekend reading: ...\n",
       "                             ...                        \n",
       "995    All kids in America should get a great educati...\n",
       "996    After Ali Maow Maalin survived the only diseas...\n",
       "997    There are few people I've learned more from th...\n",
       "998    This university is remarkable: all students, r...\n",
       "999    Bill Foege’s vision led to one of the greatest...\n",
       "Name: Text, Length: 1000, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.Text[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original:You were a good sport, Jimmy. Pro tip...never choose glass “#2” in a poop-water challenge: https://t.co/8shvjTNa4M https://t.co/onnWyhJpqm\n",
      "cleaned: good sport jimmy pro tipnever choose glass “ 2 ” poopwater challenge\n",
      "\n",
      "\n",
      "\n",
      "original:The Gates Foundation is providing additional, flexible funding to the @AfricaCDC for its pandemic response efforts, but more assistance from the global community is urgently needed to fill the gaps. https://t.co/x9k41SUi04\n",
      "cleaned: gates foundation providing additional flexible funding pandemic response efforts assistance global community urgently needed fill gaps\n",
      "\n",
      "\n",
      "\n",
      "original:Over the years, I’ve shared a stage with a jar of human feces, smelled pit latrine odor, and drunk water made from poop (and convinced @jimmyfallon to drink it too). Was it worth it? You bet. Here’s why: https://t.co/8SJbCuNezD\n",
      "cleaned: years ’ shared stage jar human feces smelled pit latrine odor drunk water made poop convinced drink worth bet ’\n",
      "\n",
      "\n",
      "\n",
      "original:I’ve been rewatching some of my favorite movies. Add your favorites to the list on @Likewise. https://t.co/bEgD4aMmSU\n",
      "cleaned: ’ rewatching favorite movies add favorites list\n",
      "\n",
      "\n",
      "\n",
      "original:Getting an early start on my weekend reading: this article does a good job explaining immunity and what may happen with COVID-19 in the future. https://t.co/AHatTlUdOr\n",
      "cleaned: getting early start weekend reading article good job explaining immunity may happen covid19 future\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tweet in test:\n",
    "    print(f\"original:{tweet}\")\n",
    "    print(f\"cleaned: {cleanTweet(tweet, verbose=False)}\")\n",
    "    print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import load_data as ld\n",
    "all_tweets = ld.get_all_tweets_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_and_save_tweets(tweets, verbose = False):\n",
    "    cleaned_tweets = []\n",
    "    for index, tweet in enumerate(tweets):\n",
    "        clean = cleanTweet(tweet)\n",
    "        cleaned_tweets.append(clean)\n",
    "        if verbose: print(f\"{index + 1}/{len(tweets)} cleaned\")\n",
    "    \n",
    "    return cleaned_tweets\n",
    "#     return list(map(lambda tweet: cleanTweet(tweet), tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- cleaning tweets of BarackObama ------------\n",
      "--------- saved cleaned tweets of BarackObama ------------\n",
      "--------- cleaning tweets of katyperry ------------\n",
      "--------- saved cleaned tweets of katyperry ------------\n",
      "--------- cleaning tweets of kanyewest ------------\n",
      "--------- saved cleaned tweets of kanyewest ------------\n",
      "--------- cleaning tweets of rihanna ------------\n",
      "--------- saved cleaned tweets of rihanna ------------\n",
      "--------- cleaning tweets of arianagrande ------------\n",
      "--------- saved cleaned tweets of arianagrande ------------\n",
      "--------- cleaning tweets of jtimberlake ------------\n",
      "--------- saved cleaned tweets of jtimberlake ------------\n",
      "--------- cleaning tweets of justinbieber ------------\n",
      "--------- saved cleaned tweets of justinbieber ------------\n",
      "--------- cleaning tweets of billgates ------------\n",
      "--------- saved cleaned tweets of billgates ------------\n",
      "--------- cleaning tweets of elonmusk ------------\n",
      "--------- saved cleaned tweets of elonmusk ------------\n",
      "--------- cleaning tweets of shakira ------------\n",
      "--------- saved cleaned tweets of shakira ------------\n",
      "--------- cleaning tweets of brunomars ------------\n",
      "--------- saved cleaned tweets of brunomars ------------\n",
      "--------- cleaning tweets of wizkhalifa ------------\n",
      "--------- saved cleaned tweets of wizkhalifa ------------\n",
      "--------- cleaning tweets of harry_styles ------------\n",
      "--------- saved cleaned tweets of harry_styles ------------\n",
      "--------- cleaning tweets of Cristiano ------------\n",
      "--------- saved cleaned tweets of Cristiano ------------\n",
      "--------- cleaning tweets of neymarjr ------------\n",
      "--------- saved cleaned tweets of neymarjr ------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "for username, tweets in all_tweets.items():\n",
    "    print(f\"--------- cleaning tweets of {username} ------------\")\n",
    "    \n",
    "    tweets_only = tweets.Text\n",
    "    cleaned = clean_and_save_tweets(tweets_only, verbose=False)\n",
    "    \n",
    "    data = {\n",
    "        \"Text\": tweets_only,\n",
    "        \"Cleaned\": cleaned\n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    load_data.save_cleaned_tweets(df, username)\n",
    "    \n",
    "    print(f\"--------- saved cleaned tweets of {username} ------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
